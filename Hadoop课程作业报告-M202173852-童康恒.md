# 一 Project内容

1. 用MapReduce算法实现贝叶斯分类器的训练过程，并输出训练模型；
2. 用输出的模型对测试集文档进行分类测试。测试过程可基于单机Java程序，也可以是MapReduce程序。输出每个测试文档的分类结果；
3. 利用测试文档的真实类别，计算分类模型的Precision，Recall和F1值。



# 二 贝叶斯分类器理论介绍

## 1 贝叶斯分类器简介

1. 贝叶斯分类器是一种**基于统计**的分类器，它根据给定样本属于某一个具体类的**概率**来对其进行分类；
2. 贝叶斯分类器的理论基础是**贝叶斯理论**；
3. 贝叶斯分类器的一种简单形式是**朴素贝叶斯分类器**，跟随机森林、神经网络等分类器都有可比的性能；
4. 贝叶斯分类器是一种**增量型**的分类器。

## 2 贝叶斯理论

1. **乘法定理**：设$P(B) > 0$，则有$P(AB) = P(A|B)P(B)$；

2. **全概率公式**：设试验$E$的样本空间为$S$，$A$为$E$的事件，若事件组$B_1，B_2，…，B_n$为$S$的一个划分，且$P(B_i) > 0(i=1，2，…，n)$，则有
	$$
	P(A)= P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + …+ P(A|B_n)P(B_n)
	$$

3. **贝叶斯公式：**设试验$E$的样本空间为$S$，$A$为$E$的事件，$B_1，B_2…，B_n$为$S$的一个划分，且$P(A)>0$，$P(B_i)>0(i=1，2，…，n)$，则有

$$
P(B_i|A) = P(AB_i)/P(A) = P(A|B_i)P(B_i)/∑P(A|B_i)P(B_i),i=1,2,…n
$$

## 3 朴素贝叶斯分类器

1. 设**$D$**为样本训练集；每一个样本$X$是由$n$个属性值组成的，$X=(x_1，x_2，…x_n)$，对应的属性集为$A_1，A_2，A_3…A_n$；
2. 假设有$m$个类标签：$C_1，C_2，…C_m$，对于某待分类元$X$，朴素分类器会把$P(C_i|X)(i=1，2，…m)$值最大的那个类标签**$C_i$**认为是$X$的类别，即朴素贝叶斯分类器预测出$X$属于类$C_i$，**当且仅当**$P(C_i|X)>P(C_j|X) (1≤j≤m，j≠i)$。因此我们的目标就是找出**$P(C_i|X)$**中的**最大**值。

$$
P(C_i|X) = P(X|C_i)P(C_i)/P(X)
$$

​		对于给定的样本集，$P(X)$是常数，跟某个具体的类标签没有关联，所以要想找出$P(C_i|X)$的最大值也就是找出$P(X|C_i)P(C_i)$的最大值：如果我们不知道$P(C_i)$的值，我们可以假设$P(C_1)=P(C_2)=…=P(C_m)$，当然$P(C_i)$可以通过估计值来代替，$P(C_i)=|C_i， D| /|D|$其中$|D|$为样本总数，$|C_i，D|$为$D$中属于类$C_i$的样本数。

3. 如果$n$的值特别大，也就是说样本元有很多属性，那么对于$P(X|C_i)$的计算会相当复杂。所以在朴素贝叶斯中进行了一个假设：即对于样本元中的每个属性，它们都**互相条件独立**。所以有：$P(X|C_i)=\prod_{k=1}^nP(x_k|C_i)$，对于$P(x_i|C_i)$我们可以从训练集中算出来,其中$x_i$代表在某个具体样本中对应属性$A_i$的值。$P(x_i|C_i)$的计算分为两种情况：

	1）：如果属性$A_i$的值是分类变量(离散变量),那么$P(x_i|C_i)$等于训练样本空间$|D|$中,属于类$C_i$并且对应属性$A_i$的值等于$x_i$的数目除以样本空间中属于类$C_i$的样本数目。

	2）：如果$A_i$的值是连续型的变量,则$P(x_i|C_i)$的计算会根据高斯分布来计算,设其中均值为$\mu$,标准方差为$\sigma$：$g(x,\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$，$P(X|C_i)=g(x_k,\mu_{C_i},\sigma_{C_i})$

4. 为了预测$X$所属的类标签,我们根据前面的步骤可以算出每一个类标签$C_i$对应的$P(X|C_i)P(C_i)$值，当某一个类标签$C_i$有：$P(X|C_i)P(C_i)>P(X|C_j)P(C_j) \space for\space any \space j:1\le j \le m,j \neq i$，则我们认为X属于标签类$C_i$。

# 三 贝叶斯分类器训练的MapReduce算法设计

​		该算法实现过程流程和框架在`Main`这个类中定义，主要分四部分：

1. 选择**数据集**，并将其划分为**训练集**和**测试集**。本实验使用的数据集包括**四**个文件夹，其中每个文件夹名即为类别标签，文件夹下的若干文档都属于该类别。根据比例随机将每个文件夹中的`.txt`文件分为训练集和测试集两部分；

2. 根据训练集中的数据，统计出每个类的**文件数**、每个类中各个**分词**的数目，并将结果保存在相应文件中。这里用到了两个`MapReduce Job`，记为`mr1`，`mr2`。根据两个`mr`统计得到的数据，可以计算出分类预测所需的先验概率和每个类别中分词出现的条件概率。具体的输入输出，以及各自的`Data Flow`示意图如下：
	`mr1`用来统计训练集中每个类别的文档数目。输入文件是训练集的所有文档，`map`输出的`key`为文档类别，`value`用来计数，都设置为`1`，可表示为`<ClassName, 1>`。将输出进行洗牌，合并有相同`key`值的`value`，以此作为`reduce`的输入。`reduce`输出的`key`为文档类别，`value`为该类别文档的总数目，可表示为`<ClassName, TotalCount>`。![mr1.drawio](C:\Users\16844\Downloads\mr1.drawio.svg)
	
	`mr2`用来统计每个类别中出现的各个分词的数目。输入文件也是训练集的所有文档。`map`输出的`key`为文档类别和分词，`value`设置为`1`，表示该分词在此文档类别中出现`1`次，可表示为`<<ClassName, Term>, 1>`。将输出进行洗牌，合并有相同`key`值的`value`，以此作为`reduce`的输入。`reduce`输出的`key`为文档类别和分词，`value`为此类别中该分词出现的总次数，可表示为`<<ClassName, Term>, TotalCount>`。![mr2.drawio](C:\Users\16844\Downloads\mr2.drawio.svg)
	
3. 由测试集数据进行预测。先对测试集数据进行处理，然后根据训练得到的结果，求出先验概率和似然概率，计算两者乘积，寻找使后验概率最大的值，以此作为测试集中待分类文档的类别。这里同样用到了两个`MapReduce Job`，记为`mr3`，`mr4`。具体的输入输出，以及各自的`Data Flow`示意图如下：
	`mr3`用来处理测试集的数据。输入文件是所有测试集，需读取文档内容（每行一个分词）。`map`的输出`key`为文档类别和文档名，`value`为对应的分词，可表示为`<<ClassName, DocumentName>, Term>`。将输出进行洗牌，合并有相同`key`值的`value`，以此作为`reduce`的输入。`reduce`的输出`key`仍为文档类别和文档名，`value`为合并后的所有`term`拼接成的字符串，可表示为`<<ClassName, DocumentName>, String>`。
